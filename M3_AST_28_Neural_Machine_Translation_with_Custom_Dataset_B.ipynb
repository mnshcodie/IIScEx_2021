{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M3_AST_28_Neural_Machine_Translation_with_Custom_Dataset_B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnshcodie/IIScEx_2021/blob/main/M3_AST_28_Neural_Machine_Translation_with_Custom_Dataset_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Nwm4FK3wgU"
      },
      "source": [
        "# Advanced Programme in Deep Learning (Foundations and Applications)\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 27: Natural Language Processing - III \n",
        "### (Translate human readable dates to machine readable dates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu26Vq9jDTpj"
      },
      "source": [
        "### Learning Objectives:\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        " \n",
        "*  perform seq2seq translation\n",
        "*  use attention architecture for machine translation tasks\n",
        "*  Visualize the parts of the input to which every output pays attention to, while doing the translation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzlYL4CDrmE"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M3_AST_28_Neural_Machine_Translation_with_Custom_Dataset_B\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/dates_dataset.csv\") \n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://dlfa.iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer1():\n",
        "  try:\n",
        "    if not Answer1:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer1\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 1\")\n",
        "    return None\n",
        "\n",
        "def getAnswer2():\n",
        "  try:\n",
        "    if not Answer2:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer2\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 2\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVM_u_Czx_jZ"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjGGk7W-nY0x"
      },
      "source": [
        "import torch,os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random,os,sys\n",
        "from babel.dates import format_date\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper methods for Human readable and machine readable dates"
      ],
      "metadata": {
        "id": "OieT0WXwE5tt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fb0rmI7bUPM"
      },
      "source": [
        "def transform(human_readable, machine_readable, human_vocab, machine_vocab, human_readable_length):\n",
        "      \n",
        "    X = list(map(lambda x: human_vocab.get(x, '<unk>'), human_readable))\n",
        "    if len(X) < human_readable_length:\n",
        "        X += [human_vocab['<pad>']] * (human_readable_length - len(X))\n",
        "    elif len(X) > human_readable_length:\n",
        "        X = X[:30]\n",
        "    Y = list(map(lambda x: machine_vocab.get(x, '<unk>'), machine_readable)) #len(Y) is always 10, because the format is YYYY-MM-DD\n",
        "\n",
        "    def zcs(length, idx):\n",
        "        ret = np.zeros(length)\n",
        "        ret[idx] = 1\n",
        "        return ret\n",
        "    \n",
        "    Xoh = np.array(list(map(partial(zcs, len(human_vocab)), X)), dtype=np.float32)\n",
        "    Yoh = np.array(list(map(partial(zcs, len(machine_vocab)), Y)), dtype=np.float32) \n",
        "    return Xoh, Yoh, {'human_readable':human_readable, 'machine_readable':machine_readable}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the csv file as dataframe"
      ],
      "metadata": {
        "id": "xKC0qdzb6Pdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read the csv file as dataframe\n",
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "IKldiEgjEDeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Class for reading data"
      ],
      "metadata": {
        "id": "bGiJ0LPxFl8H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycRSVcD8njZZ"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, transform,dates = dt_train, n_datas=40000, seed=12345):\n",
        "        self.transform = transform\n",
        "\n",
        "        self.human_readable = dt_train['human_readable']\n",
        "        self.machine_readable = dt_train['machine_readable']\n",
        "\n",
        "        self.human_readable_length = 30 #the maximum length is less than 30\n",
        "        self.human_vocab = set()\n",
        "        self.machine_vocab = set()\n",
        "        self.dataset = []\n",
        "        \n",
        "        #read the dataframe and create vocabulary \n",
        "        #YOUR CODE HERE\n",
        "\n",
        "        self.human_vocab = dict(zip(sorted(self.human_vocab) + ['<unk>', '<pad>'], list(range(len(self.human_vocab) + 2))))\n",
        "        self.inv_machine_vocab = dict(enumerate(sorted(self.machine_vocab)))\n",
        "        self.machine_vocab = {v:k for k, v in self.inv_machine_vocab.items()}\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        human_readable, machine_readable = self.dataset[idx] #dataset is a list of tuples\n",
        "        return self.transform(human_readable, machine_readable, self.human_vocab, self.machine_vocab, self.human_readable_length)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data using pytorch data loader"
      ],
      "metadata": {
        "id": "Zv-8VS7MF-SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the dataframe into 40000:10000 train:test split\n",
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "-n2G9Hn0FV-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset(dates = dt_train,transform=transform)"
      ],
      "metadata": {
        "id": "xE4_dl1xzhHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset using Pytorch Dataloader\n",
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "6ibh_kinHRfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch_x in enumerate(dataloader):\n",
        "    print(i, batch_x[0].shape, batch_x[1].shape)\n",
        "    print(batch_x[1])\n",
        "    if i >= 1:\n",
        "        break"
      ],
      "metadata": {
        "id": "bbl9g_xcHL9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NMT is a problem where we process an input sequence to produce an output sequence — that is, a sequence-to-sequence (seq2seq) problem. Specifically, the many-to-many type, with a sequence of several elements both at the input and at the output, and the encoder-decoder architecture for recurrent neural networks is the standard method.\n",
        "\n",
        "Initially machine translation (MT) problems were faced using statistical approaches, based mainly on Bayes probabilities. But when neural networks became more powerful and popular, researchers began to explore the capabilities of this technology and new solutions were found. It is called neural machine translation (NMT).\n",
        "\n",
        "The model based on RNNs has a serious problem when working with long sequences because the information of the first tokens is lost or diluted as more tokens are processed. The context vector has been given the responsibility of encoding all of the information in a given source sentence into a vector of few hundred elements. It made it challenging for the models to deal with long sentences. \n",
        "\n",
        "In this paper https://arxiv.org/pdf/1409.0473.pdf\n",
        "\n",
        "\n",
        "They introduce a technique called attention, which highly improved the quality of machine-translation systems. “Attention allows the model to focus on the relevant parts of the input sequence as needed, accessing all the past hidden states of the encoder, instead of just the last one”. At each decoding step, the decoder gets to look at any particular state of the encoder and can selectively pick out specific elements from that sequence to produce the output."
      ],
      "metadata": {
        "id": "trChpcm7LNTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![seq2seq.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "xdJRckK9KNG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder architecture"
      ],
      "metadata": {
        "id": "awDs4pVUOZxi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNZb1nQsbaY7"
      },
      "source": [
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, in_features=37, hidden_size=64):\n",
        "        super(Encoder, self).__init__()\n",
        "        #Encoder archiecture\n",
        "        #YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder architecture"
      ],
      "metadata": {
        "id": "e2b0EVasOeJp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwa8iQoWnrw4"
      },
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, in_features=128, hidden_size=128):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        #Decoder architecture\n",
        "        #YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining Encoder-Attention-Decoder"
      ],
      "metadata": {
        "id": "5a5a6qELOkQ4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haQF38TAnxIo"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, output_len, use_gpu=True):\n",
        "        super(Model, self).__init__()\n",
        "        self.output_len = output_len\n",
        "        self.use_gpu = use_gpu\n",
        "        self.encoder = Encoder(in_features=36, hidden_size=64)\n",
        "        self.decoder = Decoder(in_features=128, hidden_size=128)\n",
        "        \n",
        "        #attention net\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.encoder(x) #(N, 30, 128)\n",
        "        if self.use_gpu:\n",
        "            decoder_h = torch.zeros((1, feats.shape[0], 128)).cuda() #(1, N, 128)\n",
        "            decoder_c = torch.zeros((1, feats.shape[0], 128)).cuda() #(1, N, 128)\n",
        "        else:\n",
        "            decoder_h = torch.zeros((1, feats.shape[0], 128)) #(1, N, 128)\n",
        "            decoder_c = torch.zeros((1, feats.shape[0], 128)) #(1, N, 128)\n",
        "        # print(feats.shape, decoder_c.shape)\n",
        "        outputs = []\n",
        "        self.scores_for_paint = []\n",
        "        for _ in range(self.output_len):\n",
        "            feats_2 = decoder_c.transpose(0, 1) #(1, N, 128) --> (N, 1, 128)\n",
        "            feats_2 = feats_2.repeat(1, feats.shape[1], 1) #(N, 1, 128) --> (N, 30, 128), cuz feats.shape[1] is 30\n",
        "            feats_in = torch.cat((feats, feats_2), dim=-1) # (N, 30, 128) and (N, 30, 128) --> (N, 30, 256)\n",
        "            # print(feats.shape, feats_2.shape, feats_in.shape)\n",
        "            out = self.tanh(self.linear1(feats_in)) #(N, 30, 256) --> (N, 30, 10)\n",
        "            scores = self.softmax(self.linear2(out)) #(N, 30, 10) --> (N, 30, 1)\n",
        "            # print(scores[0, :, 0])\n",
        "\n",
        "            if not self.training:\n",
        "                self.scores_for_paint.append(scores.squeeze().detach().cpu().numpy())\n",
        "                # print(scores)\n",
        "            \n",
        "            \n",
        "\n",
        "            feats_for_decoder = torch.mul(feats, scores).sum(axis=1).unsqueeze(1) #(N, 30, 128) mul (N, 30, 1) --> (N, 30, 128) --> (N, 128) --> (N, 1, 128)\n",
        "            \n",
        "\n",
        "            decoder_out, (decoder_h, decoder_c) = self.decoder(feats_for_decoder, decoder_h, decoder_c) #run lstm only one step, cuz feats_for_decoder.shape is (N, 1, 128)\n",
        "            outputs.append(decoder_out.unsqueeze(1)) #list of (N, 1, 11)\n",
        "            # print(decoder_out.shape)\n",
        "        outputs = torch.cat(outputs, dim=1) #(N, 10, 11) 10是输出序列长度\n",
        "        # print(outputs.shape)\n",
        "        return outputs\n",
        "\n",
        "    def total_parameters(self):\n",
        "        return sum([p.numel() for p in self.parameters()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le_TKOMvnzcA"
      },
      "source": [
        "\n",
        "\n",
        "model = Model(output_len=13, use_gpu=False)\n",
        "print('model size is %.3f KB' % (model.total_parameters() * 4 / 1024))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper function for calculating accuracy"
      ],
      "metadata": {
        "id": "QqIu8uIPPAyF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGG0NBQGoKBI"
      },
      "source": [
        "#Method for calculaing accuracy\n",
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper function for training the attention network"
      ],
      "metadata": {
        "id": "05WkQY-GPGPE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGt063tMujuu"
      },
      "source": [
        "def train(model, loss_fn, optimizer, dataloader, epoch, use_gpu=False):\n",
        "    pbar = tqdm(total=len(dataloader), bar_format='{l_bar}{r_bar}', dynamic_ncols=True)\n",
        "    pbar.set_description(f'Epoch %d' % epoch)\n",
        "\n",
        "    for step, (batch_x, batch_y, _) in enumerate(dataloader):\n",
        "        \n",
        "        #code for training the model and calculate loss\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "        pbar.set_postfix(**{'loss':loss.detach().cpu().item(), 'accuracy':accuracy})\n",
        "        pbar.update()\n",
        "    save_checkpoint('./checkpoint', epoch, model, optimizer)\n",
        "\n",
        "    pbar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the model checkpoints"
      ],
      "metadata": {
        "id": "LSjpImUBPPGY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9557DeNwnb9"
      },
      "source": [
        "def find_last_checkpoint(checkpoint_dir):\n",
        "    epochs = []\n",
        "    for name in os.listdir(checkpoint_dir):\n",
        "        if os.path.splitext(name)[-1] == '.pth':\n",
        "            epochs += [int(name.strip('ckpt_epoch_.pth'))]\n",
        "    if len(epochs) == 0:\n",
        "        raise IOError('no checkpoint found in {}'.format(checkpoint_dir))\n",
        "    return max(epochs)\n",
        "\n",
        "def save_checkpoint(checkpoint_dir, epoch, model, optimizer=None):\n",
        "    checkpoint = {}\n",
        "    checkpoint['epoch'] = epoch\n",
        "\n",
        "    if isinstance(model, torch.nn.DataParallel):\n",
        "        model_state_dict = model.module.state_dict()\n",
        "    else:\n",
        "        model_state_dict = model.state_dict()\n",
        "    checkpoint['model'] = model_state_dict\n",
        "\n",
        "    if optimizer is not None:\n",
        "        optimizer_state_dict = optimizer.state_dict()\n",
        "        # for k, v in optimizer_state_dict.items():\n",
        "        #     print(k, type(v))\n",
        "        # optimizer_state_dict = rename_dict_key(optimizer_state_dict)\n",
        "        checkpoint['optimizer'] = optimizer_state_dict\n",
        "    else:\n",
        "        checkpoint['optimizer'] = None\n",
        "\n",
        "    torch.save(checkpoint, os.path.join(checkpoint_dir, 'ckpt_epoch_%02d.pth'% epoch))\n",
        "\n",
        "def load_checkpoint(checkpoint_dir, epoch=-1):\n",
        "    if epoch == -1:\n",
        "        epoch = find_last_checkpoint(checkpoint_dir)\n",
        "    checkpoint_name = 'ckpt_epoch_%02d.pth'% epoch\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name)\n",
        "    ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
        "    return ckpt\n",
        "\n",
        "def save_model(checkpoint_dir, epoch, model):\n",
        "    save_checkpoint(checkpoint_dir, epoch, model, optimizer=None)\n",
        "\n",
        "def load_model(checkpoint_dir, epoch, model):\n",
        "    try:\n",
        "        ckpt = load_checkpoint(checkpoint_dir, epoch)\n",
        "        model_state_dict = ckpt['model']\n",
        "\n",
        "        if isinstance(model, torch.nn.DataParallel):\n",
        "            model.module.load_state_dict(model_state_dict)\n",
        "        # elif isinstance(model, torchDDP):\n",
        "        #     model.module.load_state_dict(model_state_dict)\n",
        "        # elif isinstance(model, apexDDP):\n",
        "        #     model.module.load_state_dict(model_state_dict)\n",
        "        else:\n",
        "            model.load_state_dict(model_state_dict)\n",
        "    except Exception as e:\n",
        "        print('failed to load model, {}'.format(e))\n",
        "    return model\n",
        "\n",
        "def load_optimizer(checkpoint_dir, epoch, optimizer):\n",
        "    try:\n",
        "        ckpt = load_checkpoint(checkpoint_dir, epoch)\n",
        "        optimizer_state_dict = ckpt['optimizer']\n",
        "        optimizer.load_state_dict(optimizer_state_dict)\n",
        "    except Exception as e:\n",
        "        print('failed to load optimizer, {}'.format(e))\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "SnS1H4lvPW0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"checkpoint\"):\n",
        "  os.mkdir(\"checkpoint\")"
      ],
      "metadata": {
        "id": "XR98aIea0T6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a8uDfNWb6IX"
      },
      "source": [
        "def main(dataloader,gpu_id=None,):\n",
        "\n",
        "    dataloader = dataloader\n",
        "\n",
        "    #Initiate and train the model\n",
        "    #YOUR CODE HERE\n",
        "\n",
        "    model = load_model('./checkpoint', -1, model)\n",
        "    optimizer = load_optimizer('./checkpoint', -1, optimizer)\n",
        "\n",
        "    try:\n",
        "        trained_epoch = find_last_checkpoint('./checkpoint')\n",
        "        print('train form epoch %d' % (trained_epoch + 1))\n",
        "    except Exception as e:\n",
        "        print('train from the very begining, {}'.format(e))\n",
        "        trained_epoch = -1\n",
        "    for epoch in range(trained_epoch+1, 20):\n",
        "        train(model, loss_fn, optimizer, dataloader, epoch, use_gpu=True if gpu_id is not None else False)\n",
        "\n",
        "\n",
        "if len(sys.argv) == 1:\n",
        "    main(dataloader,gpu_id='0')\n",
        "else:\n",
        "    main(dataloader,gpu_id=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model with 10000 test examples"
      ],
      "metadata": {
        "id": "eOTJwvplDeYj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFIuxaibl95S"
      },
      "source": [
        "#load the dataset for testing model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model \n",
        "#### Here we are evaulating the model and plotting the attention"
      ],
      "metadata": {
        "id": "XoGk_FcmDvdQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buSm7Jf_pRnC"
      },
      "source": [
        "\n",
        "model = Model(output_len=10, use_gpu=False)\n",
        "try:\n",
        "    trained_epoch = find_last_checkpoint('./checkpoint')\n",
        "    print('load model %d' % (trained_epoch))\n",
        "except Exception as e:\n",
        "    print('no trained model found, {}'.format(e))\n",
        "\n",
        "model = load_model('./checkpoint', -1, model)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "#Plot the attention plots of test data \n",
        "#YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating the accuracy"
      ],
      "metadata": {
        "id": "wne5QS_uEBxi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHFs3rYapWZ5"
      },
      "source": [
        "#Calculate the test set accuracy\n",
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlhryqWxbXMz",
        "cellView": "form"
      },
      "source": [
        "#@title Q.1. In the encoder, the fixed length vector at the output represents _______________  ?\n",
        "Answer1 = \"\" #@param [\"\",\"Word vector\",\"Encoding of the input sentence\",\"Translation of the sentence\",\"Softmax containing the probability score of all words in the vocabulary\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8R6F2KGyiwk",
        "cellView": "form"
      },
      "source": [
        "#@title Q.2. Why is an RNN (Recurrent Neural Network) used for machine translation,say translating English to German ? \n",
        "Answer2 = \"\" #@param [\"\",\"RNNs do not have problem of vanishing gradient\",\"It is strictly powerful than a Convolutional Neural Network(CNN)\",\"It is applicable when the input/output is a sequence (e.g., a sequence of words)\",\"None of the above\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}